{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM Models on crypto price trend prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-fe8fefc5e734>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Preliminary code needed for importing from parent directory\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "# Import data API\n",
    "from data import series\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# This classifier first converts the target values into {-1, 1} and then treats the problem as a regression task\n",
    "# (multi-output regression in the multiclass case).\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import talib as ta\n",
    "from talib import MA_Type\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def gen_X_y(symbol: str, timeframe: str):\n",
    "    # Create a series for BTC-USDT pair on 1h candles\n",
    "    # btc = series.DataSeries('BTCUSDT', '1h')\n",
    "    btc = series.DataSeries(symbol, timeframe)\n",
    "    data = btc.getData()\n",
    "    #data\n",
    "    # print(data.keys())\n",
    "\n",
    "    price_close = data['close']\n",
    "    # print(len(price_close))\n",
    "    \n",
    "    prev5 = np.concatenate([\n",
    "            # pivot timeframe\n",
    "            price_close[np.newaxis, 5:],\n",
    "            # previous 5 timeframes\n",
    "            price_close[np.newaxis, 4:-1], # 1 frame ago\n",
    "            price_close[np.newaxis, 3:-2], # 2 frame ago\n",
    "            price_close[np.newaxis, 2:-3], # 3 frame ago\n",
    "            price_close[np.newaxis, 1:-4], # 4 frame ago\n",
    "            price_close[np.newaxis, :-5],  # 5 frame ago\n",
    "        ],\n",
    "        axis = 0\n",
    "    )\n",
    "\n",
    "    # Generate truth values (y)\n",
    "    y = prev5[0, :] > np.amin(prev5[1:, :], axis = 0)\n",
    "#     print('timeframe:', timeframe)\n",
    "#     print('number of times where trend is up: ', y[y == True].shape)\n",
    "#     print('number of times where trend is down: ', y[y == False].shape)\n",
    "    \n",
    "    btc.addIndicator('RSI', data['close'], 30) # 30-timeframe RSI\n",
    "\n",
    "    btc.addIndicator('EMA', data['close'], 30) # 30-timeframe EMA\n",
    "    # btc1h.addIndicator('EMA', btc1h.getData()['close'], 50) # 50-timeframe EMA\n",
    "\n",
    "    ## MFI: https://www.investopedia.com/terms/m/mfi.asp\n",
    "    btc.addIndicator('MFI', data['high'], data['low'], data['close'], data['volume'], 10) # 10-timeframe MFI\n",
    "\n",
    "    ## MACD: https://www.investopedia.com/terms/m/macd.asp\n",
    "    btc.addIndicator('MACD', data['close'], 12, 26) # fast = 12, slow = 26\n",
    "\n",
    "    indicators = btc.getIndicators()\n",
    "    #for indicator in indicators.keys():\n",
    "        #print(indicator)\n",
    "      \n",
    "    time_cut = 50\n",
    "\n",
    "    # Each technical indicator consists one column of X.\n",
    "    X = np.concatenate(\n",
    "        (\n",
    "            indicators['RSI'][np.newaxis, time_cut:].T,\n",
    "            indicators['EMA'][np.newaxis, time_cut:].T,\n",
    "            indicators['MFI'][np.newaxis, time_cut:].T\n",
    "        ),\n",
    "        axis = 1\n",
    "    )\n",
    "    \n",
    "   # X_1 =my_data.loc[:, my_data.columns != 'y']\n",
    "    # print('shape of X:', X.shape)\n",
    "    # print('shape of y:', y.shape)\n",
    "\n",
    "    y_truncate = y[(time_cut - 5):]\n",
    "    \n",
    "    return (X, y_truncate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hour timeframe data, correcting imbalanced data, creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X, y generated from 1h-scale data\n",
      "train set size: (22967,)\n",
      "test set size: (7656,)\n",
      "hour scale price data\n",
      "True count: 24621\n",
      "False count: 6002\n",
      "Train set True/False ratio: 4492 / 4511\n",
      "Test set True/False ratio: 1510 / 1491\n"
     ]
    }
   ],
   "source": [
    "X_h, y_h = gen_X_y('BTCUSDT', '1h')\n",
    "\n",
    "\n",
    "# Split train/test sets\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(X_h, y_h)\n",
    "print('X, y generated from 1h-scale data')\n",
    "print('train set size:', y_train_h.shape)\n",
    "print('test set size:', y_test_h.shape)\n",
    "\n",
    "\n",
    "\n",
    "print('hour scale price data')\n",
    "print('True count:', len(y_h[y_h == True]))\n",
    "print('False count:', len(y_h[y_h == False]))\n",
    "\n",
    "indices = np.where(y_h == True)[0]\n",
    "if len(y_h[y_h == True]) > len(y_h[y_h == False]):\n",
    "    indices = np.random.choice(indices, size = len(y_h[y_h == False]), replace = False)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "# Combine the `True` indices with `False` indices\n",
    "indices = np.concatenate((indices, np.where(y_h == False)[0]))\n",
    "seed =1234\n",
    "X_train_h_even, X_test_h_even, y_train_h_even, y_test_h_even = train_test_split(X_h[indices], y_h[indices])\n",
    "print('Train set True/False ratio:', len(np.where(y_train_h_even == True)[0]), '/', len(np.where(y_train_h_even == False)[0]))\n",
    "print('Test set True/False ratio:', len(np.where(y_test_h_even == True)[0]), '/', len(np.where(y_test_h_even == False)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day timeframe data, correcting imbalanced data, creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X, y generated from 1d-scale data\n",
      "train set size: (924,)\n",
      "test set size: (309,)\n",
      "day scale price data\n",
      "True count: 1000\n",
      "False count: 233\n",
      "Total dataset size (train + test): 466\n",
      "Train set True/False ratio: 173 / 176\n",
      "Test set True/False ratio: 60 / 57\n"
     ]
    }
   ],
   "source": [
    "X_d, y_d = gen_X_y('BTCUSDT', '1d')\n",
    "\n",
    "# Split train/test sets\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_d, y_d)\n",
    "print('X, y generated from 1d-scale data')\n",
    "print('train set size:', y_train_d.shape)\n",
    "print('test set size:', y_test_d.shape)\n",
    "\n",
    "print('day scale price data')\n",
    "print('True count:', len(y_d[y_d == True]))\n",
    "print('False count:', len(y_d[y_d == False]))\n",
    "\n",
    "indices = np.where(y_d == True)[0]\n",
    "if len(y_d[y_d == True]) > len(y_d[y_d == False]):\n",
    "    indices = np.random.choice(indices, size = len(y_d[y_d == False]), replace = False)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "# Combine the `True` indices with `False` indices\n",
    "indices = np.concatenate((indices, np.where(y_d == False)[0]))\n",
    "seed =1234\n",
    "X_train_d_even, X_test_d_even, y_train_d_even, y_test_d_even = train_test_split(X_d[indices], y_d[indices])\n",
    "print('Total dataset size (train + test):', indices.shape[0])\n",
    "print('Train set True/False ratio:', len(np.where(y_train_d_even == True)[0]), '/', len(np.where(y_train_d_even == False)[0]))\n",
    "print('Test set True/False ratio:', len(np.where(y_test_d_even == True)[0]), '/', len(np.where(y_test_d_even == False)[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the SVM Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale all the x variables \n",
    "scaled_x_train = StandardScaler().fit_transform(X_train_d_even)\n",
    "scaled_x_test=StandardScaler().fit_transform(X_test_d_even)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the svm model with no parameter tuning \n",
    "svmmodel = SVC(gamma='auto')\n",
    "svmmodel.fit(X_train_d_even, y_train_d_even)\n",
    "y_predict_train = svmmodel.predict(scaled_x_train)\n",
    "y_predict_test = svmmodel.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.504297994269341"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the train-set accuracy \n",
    "train_accuracy = accuracy_score(y_train_d_even,y_predict_train)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48717948717948717"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the test-set accuracy \n",
    "test_accuracy = accuracy_score(y_test_d_even,y_predict_test)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(gamma='auto'), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
       "                         'kernel': ('linear', 'rbf')},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter Tuning using different Kernel and different values of C\n",
    "\n",
    "svm_parameters = {'kernel':('linear', 'rbf'), 'C':[0.001,0.01, 0.1, 1.0,10.0, 100.0,1000.0]}\n",
    "        # ADD CODE HERE\n",
    "svc = SVC(gamma='auto')\n",
    "svm_cv = GridSearchCV(svc,svm_parameters,n_jobs=-1,return_train_score=True)\n",
    "svm_cv.fit(scaled_x_train,y_train_d_even)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.676231884057971"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best score for the svm model \n",
    "best_score= svm_cv.best_score_\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train = svm_cv.predict(scaled_x_train)\n",
    "y_predict_test = svm_cv.predict(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = accuracy_score(y_train_d_even, y_predict_train)\n",
    "test_accuracy = accuracy_score(y_test_d_even, y_predict_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7106017191977078\n",
      "0.6410256410256411\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 13,  9, 13,  2,  3,  4,  1,  4,  8,  4, 10,  4, 11])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_test_score = svm_cv.cv_results_['rank_test_score']\n",
    "rank_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51585921, 0.50430642, 0.66761905, 0.50430642, 0.67619048,\n",
       "       0.67333333, 0.67329193, 0.67623188, 0.67329193, 0.6705176 ,\n",
       "       0.67329193, 0.63602484, 0.67329193, 0.61022774])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_score = svm_cv.cv_results_['mean_test_score']\n",
    "mean_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00979605, 0.00800042, 0.00879974, 0.0075994 , 0.00559921,\n",
       "        0.01180129, 0.00760055, 0.00731792, 0.01360145, 0.00840025,\n",
       "        0.08836265, 0.02435942, 0.47980084, 0.21229291]),\n",
       " 'std_fit_time': array([0.00247779, 0.00063295, 0.0044463 , 0.00079914, 0.00185566,\n",
       "        0.0059809 , 0.00320005, 0.00077481, 0.00265347, 0.0010194 ,\n",
       "        0.02559945, 0.00238946, 0.09183802, 0.07576667]),\n",
       " 'mean_score_time': array([0.00280128, 0.00280099, 0.00139999, 0.00240097, 0.00280228,\n",
       "        0.00219946, 0.00140109, 0.00182891, 0.00199962, 0.0015996 ,\n",
       "        0.00760002, 0.00179963, 0.00406995, 0.00140061]),\n",
       " 'std_score_time': array([0.00074746, 0.00075026, 0.00049008, 0.00049059, 0.00098024,\n",
       "        0.00040028, 0.00049035, 0.00050956, 0.00063196, 0.0004908 ,\n",
       "        0.01072528, 0.00097973, 0.00538178, 0.00048831]),\n",
       " 'param_C': masked_array(data=[0.001, 0.001, 0.01, 0.01, 0.1, 0.1, 1.0, 1.0, 10.0,\n",
       "                    10.0, 100.0, 100.0, 1000.0, 1000.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1.0, 'kernel': 'linear'},\n",
       "  {'C': 1.0, 'kernel': 'rbf'},\n",
       "  {'C': 10.0, 'kernel': 'linear'},\n",
       "  {'C': 10.0, 'kernel': 'rbf'},\n",
       "  {'C': 100.0, 'kernel': 'linear'},\n",
       "  {'C': 100.0, 'kernel': 'rbf'},\n",
       "  {'C': 1000.0, 'kernel': 'linear'},\n",
       "  {'C': 1000.0, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.51428571, 0.51428571, 0.71428571, 0.51428571, 0.71428571,\n",
       "        0.72857143, 0.72857143, 0.74285714, 0.72857143, 0.77142857,\n",
       "        0.72857143, 0.71428571, 0.72857143, 0.68571429]),\n",
       " 'split1_test_score': array([0.5       , 0.5       , 0.62857143, 0.5       , 0.67142857,\n",
       "        0.65714286, 0.67142857, 0.67142857, 0.67142857, 0.68571429,\n",
       "        0.67142857, 0.64285714, 0.67142857, 0.62857143]),\n",
       " 'split2_test_score': array([0.51428571, 0.5       , 0.64285714, 0.5       , 0.64285714,\n",
       "        0.61428571, 0.62857143, 0.61428571, 0.62857143, 0.6       ,\n",
       "        0.62857143, 0.58571429, 0.62857143, 0.55714286]),\n",
       " 'split3_test_score': array([0.5       , 0.5       , 0.68571429, 0.5       , 0.68571429,\n",
       "        0.7       , 0.68571429, 0.67142857, 0.68571429, 0.61428571,\n",
       "        0.68571429, 0.62857143, 0.68571429, 0.6       ]),\n",
       " 'split4_test_score': array([0.55072464, 0.50724638, 0.66666667, 0.50724638, 0.66666667,\n",
       "        0.66666667, 0.65217391, 0.68115942, 0.65217391, 0.68115942,\n",
       "        0.65217391, 0.60869565, 0.65217391, 0.57971014]),\n",
       " 'mean_test_score': array([0.51585921, 0.50430642, 0.66761905, 0.50430642, 0.67619048,\n",
       "        0.67333333, 0.67329193, 0.67623188, 0.67329193, 0.6705176 ,\n",
       "        0.67329193, 0.63602484, 0.67329193, 0.61022774]),\n",
       " 'std_test_score': array([0.01856652, 0.00572478, 0.03047619, 0.00572478, 0.02352207,\n",
       "        0.03887301, 0.03364373, 0.0408575 , 0.03364373, 0.06109332,\n",
       "        0.03364373, 0.04360054, 0.03364373, 0.04447166]),\n",
       " 'rank_test_score': array([12, 13,  9, 13,  2,  3,  4,  1,  4,  8,  4, 10,  4, 11]),\n",
       " 'split0_train_score': array([0.52688172, 0.50179211, 0.6702509 , 0.50179211, 0.68100358,\n",
       "        0.68100358, 0.67741935, 0.68458781, 0.67741935, 0.70609319,\n",
       "        0.67741935, 0.73476703, 0.67741935, 0.7562724 ]),\n",
       " 'split1_train_score': array([0.51612903, 0.50537634, 0.67741935, 0.50537634, 0.71326165,\n",
       "        0.70967742, 0.70967742, 0.72043011, 0.70967742, 0.72401434,\n",
       "        0.70967742, 0.74910394, 0.70967742, 0.77419355]),\n",
       " 'split2_train_score': array([0.5125448 , 0.50537634, 0.67383513, 0.50537634, 0.71326165,\n",
       "        0.70967742, 0.72759857, 0.72401434, 0.72759857, 0.7311828 ,\n",
       "        0.72759857, 0.74193548, 0.72759857, 0.79569892]),\n",
       " 'split3_train_score': array([0.50537634, 0.50537634, 0.6702509 , 0.50537634, 0.70609319,\n",
       "        0.69892473, 0.70609319, 0.70250896, 0.70609319, 0.7311828 ,\n",
       "        0.70609319, 0.74910394, 0.70609319, 0.76344086]),\n",
       " 'split4_train_score': array([0.51071429, 0.50357143, 0.67857143, 0.50357143, 0.68928571,\n",
       "        0.69642857, 0.68928571, 0.70714286, 0.69285714, 0.71785714,\n",
       "        0.69285714, 0.72857143, 0.69285714, 0.75      ]),\n",
       " 'mean_train_score': array([0.51432924, 0.50429852, 0.67406554, 0.50429852, 0.70058116,\n",
       "        0.69914235, 0.70201485, 0.70773682, 0.70272913, 0.72206605,\n",
       "        0.70272913, 0.74069636, 0.70272913, 0.76792115]),\n",
       " 'std_train_score': array([0.00717231, 0.00143498, 0.00348446, 0.00143498, 0.01313652,\n",
       "        0.0105679 , 0.01730228, 0.01406867, 0.01682929, 0.00941141,\n",
       "        0.01682929, 0.00806327, 0.01682929, 0.01604919])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv.cv_results_\n",
    "\n",
    "# lin 0.01, rbf 0.01, lin 0.1, rbf 0.1, lin 1.0, rbf 1.0 \n",
    "#0.66761905, 0.50430642, 0.67619048, 0.67333333, 0.67329193, 0.67623188\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
