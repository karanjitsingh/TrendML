{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary code needed for importing from parent directory\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "# Import Karan's data API\n",
    "from data import series\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html?highlight=pca#sklearn.decomposition.PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Features & check stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeframe: 1h\n",
      "number of times where trend is up:  (24655,)\n",
      "number of times where trend is down:  (6013,)\n",
      "RSI\n",
      "EMA\n",
      "SMA\n",
      "ADX\n",
      "ATR\n",
      "MFI\n"
     ]
    }
   ],
   "source": [
    "# Create a series for BTC-USDT pair on 1h candles\n",
    "symbol = 'BTCUSDT'\n",
    "timeframe = '1h'\n",
    "\n",
    "btc = series.DataSeries(symbol, timeframe)\n",
    "data = btc.getData()\n",
    "# print(data.keys())\n",
    "\n",
    "price_close = data['close']\n",
    "# print(len(price_close))\n",
    "\n",
    "prev5 = np.concatenate([\n",
    "        # pivot timeframe\n",
    "        price_close[np.newaxis, 5:],\n",
    "        # previous 5 timeframes\n",
    "        price_close[np.newaxis, 4:-1], # 1 frame ago\n",
    "        price_close[np.newaxis, 3:-2], # 2 frame ago\n",
    "        price_close[np.newaxis, 2:-3], # 3 frame ago\n",
    "        price_close[np.newaxis, 1:-4], # 4 frame ago\n",
    "        price_close[np.newaxis, :-5],  # 5 frame ago\n",
    "    ],\n",
    "    axis = 0\n",
    ")\n",
    "\n",
    "# Generate truth values (y)\n",
    "y = prev5[0, :] > np.amin(prev5[1:, :], axis = 0)\n",
    "print('timeframe:', timeframe)\n",
    "print('number of times where trend is up: ', y[y == True].shape)\n",
    "print('number of times where trend is down: ', y[y == False].shape)\n",
    "\n",
    "btc.addIndicator('RSI', data['close'], 14) # 14-timeframe RSI\n",
    "\n",
    "btc.addIndicator('EMA', data['close'], 30) # 30-timeframe EMA\n",
    "# btc1h.addIndicator('EMA', btc1h.getData()['close'], 50) # 50-timeframe EMA\n",
    "\n",
    "btc.addIndicator('SMA', data['close'], 30)\n",
    "\n",
    "# ADX - Average Directional Movement Index\n",
    "btc.addIndicator('ADX', data['high'], data['low'], data['close'], 14) # 14-timeframe ADX\n",
    "\n",
    "# ATR - Average True Range\n",
    "btc.addIndicator('ATR', data['high'], data['low'], data['close'], 14) # 14-timeframe ATR\n",
    "\n",
    "## MFI: https://www.investopedia.com/terms/m/mfi.asp\n",
    "btc.addIndicator('MFI', data['high'], data['low'], data['close'], data['volume'], 10) # 10-timeframe MFI\n",
    "\n",
    "## MACD: https://www.investopedia.com/terms/m/macd.asp\n",
    "# btc.addIndicator('MACD', data['close'], 12, 26) # fast = 12, slow = 26\n",
    "\n",
    "indicators = btc.getIndicators()\n",
    "for indicator in indicators.keys():\n",
    "    print(indicator)\n",
    "    \n",
    "time_cut = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why standardization is needed before PCA\n",
    "* https://www.reneshbedre.com/blog/principal-component-analysis.html#standardization\n",
    "* https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline of standardization & PCA\n",
    "\n",
    "pipeline = Pipeline([('scaling', StandardScaler()), ('pca', PCA(n_components=5))])\n",
    "\n",
    "# pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
